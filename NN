#libraries
import torch
import torch.nn as tnn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import datetime as dt
import torch.nn as nn
import torch.nn.functional as F



#checking for cpu/gpu
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
#fast training with cuda
#slow training with cpu
#CUDA is a parallel computing platform by NVIDIA
print(device)


#hyper parameters

#batch size depends upon calculations
batch_size = 10

#lr = learning rate = 0 no learning, more than 0 high learning
lr = 0.01
#epochs represents the number of cycles through training dataset
epoch = 10
classes =10


#performing transformations on images
#data processing using compose function
transform = transforms.Compose([
                                
     #resizing with crop images                        
    transforms.RandomResizedCrop(224),

    #by default flip is 0.5
    transforms.RandomHorizontalFlip(),

    #change pixel range from
    #0-255 to 0-1
    #numpy arrays to tensor
    transforms.ToTensor(),

    #mean and deviation 0.5 for each column of rgb channels but here using different values
                         #formula (x-mean)/st. dev
                         #0-1 to [-1,1]
    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],
                         std  = [ 0.229, 0.224, 0.225 ]),

                          #we can use random resize only and vertical flip
    #but we can not use vertical flip because it has vehicles
    ])
    
    
 
#cifar is a data set and we are downloading it for training, and shuffling it 
trainData = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
testData = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
trainLoader = torch.utils.data.DataLoader(trainData, batch_size=batch_size, shuffle=True)
testLoader = torch.utils.data.DataLoader(testData, batch_size=batch_size, shuffle=False)



#defining convolutional layers of the model

def conv_layer(chann_in, chann_out, k_size, p_size):
    layer = tnn.Sequential(
        tnn.Conv2d(chann_in, chann_out, kernel_size=k_size, padding=p_size),
        tnn.BatchNorm2d(chann_out),
        tnn.ReLU()
    )
    return layer

def vgg_conv_block(in_list, out_list, k_list, p_list, pooling_k, pooling_s):

    layers = [ conv_layer(in_list[i], out_list[i], k_list[i], p_list[i]) for i in range(len(in_list)) ]
    layers += [ tnn.MaxPool2d(kernel_size = pooling_k, stride = pooling_s)]
    return tnn.Sequential(*layers)


#fc is a fully connected layer which works on linear or flattened input and is connected to neurons
def vgg_fc_layer(size_in, size_out):
    layer = tnn.Sequential(
        tnn.Linear(size_in, size_out),
        tnn.BatchNorm1d(size_out),
        tnn.ReLU()
    )
    return layer



#using VGG16 model
class VGG16(tnn.Module):
    def __init__(self, n_classes=1000):
        super(VGG16, self).__init__()

        # Conv blocks BatchNorm + ReLU activation added in each block of the layers
        self.layer1 = vgg_conv_block([3,64], [64,64], [3,3], [1,1], 2, 2)
        self.layer2 = vgg_conv_block([64,128], [128,128], [3,3], [1,1], 2, 2)
        self.layer3 = vgg_conv_block([128,256,256], [256,256,256], [3,3,3], [1,1,1], 2, 2)
        self.layer4 = vgg_conv_block([256,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)
        self.layer5 = vgg_conv_block([512,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)

        # FC layers
        self.layer6 = vgg_fc_layer(7*7*512, 4096)
        self.layer7 = vgg_fc_layer(4096, 4096)

        # Final layer
        self.layer8 = tnn.Linear(4096, n_classes)

    #forward function for output
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        vgg16_features = self.layer5(out)
        out = vgg16_features.view(out.size(0), -1)
        out = self.layer6(out)
        out = self.layer7(out)
        out = self.layer8(out)

        return vgg16_features, out



#using cifar 10 dataset 10 classes       
vgg16 = VGG16(n_classes=classes)

#using cuda for high processinf
vgg16.cuda()

# using cross entropy loss function as it is optimal
cost = tnn.CrossEntropyLoss()

#using Adam optimizer, here we can use SGD
optimizer = torch.optim.Adam(vgg16.parameters(), lr=lr)


scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)

#training the model
for epoch in range(epoch):

    avg_loss = 0
    cnt = 0
    for images, labels in trainLoader:
        images = images.cuda()
        labels = labels.cuda()

        # Forward + Backward + Optimize
        optimizer.zero_grad()
        _, outputs = vgg16(images)

        #checks for loss by matching outputs with their labels
        loss = cost(outputs, labels)
        avg_loss += loss.data

        #count function is incremented in each iteration
        cnt += 1

        #printing the epoch number, loss of data and average loss/ count to see the average loss
        print("[E: %d] loss: %f, avg_loss: %f" % (epoch, loss.data, avg_loss/cnt))

        #going backward in neural network 
        loss.backward()
        optimizer.step()
    scheduler.step(avg_loss)

# Test the model
vgg16.eval()
correct = 0
total = 0


#testing the data
for images, labels in testLoader:
    images = images.cuda()
    _, outputs = vgg16(images)
    _, predicted = torch.max(outputs.data, 1)
    
    #calculating the total of predicted
    total += labels.size(0)

    correct += (predicted.cpu() == labels).sum()
    print(predicted, labels, correct, total)
    print("avg acc: %f" % (100* correct/total))

#saving the trained model
torch.save(vgg16.state_dict(), 'cnn.pkl')








